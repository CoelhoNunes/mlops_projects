# MLOps Project Configuration
# Environment variables can override any of these settings

# Data Configuration
data:
  # Paths to CSV files (supports glob patterns)
  paths: ["./mlops/data/*.csv"]
  # Target column name (auto-detected if not specified)
  target_column: null
  # Task type: auto, classification, or regression
  task_type: "auto"
  # Merge key if multiple CSVs (null for single file)
  merge_key: null
  
  # Data splitting configuration
  split:
    train_ratio: 0.7
    val_ratio: 0.15
    test_ratio: 0.15
    random_state: 42
    # Enable time-aware splitting if timestamp column exists
    time_aware: false
    timestamp_column: null
  
  # Cross-validation settings
  cv:
    n_folds: 5
    random_state: 42
    stratified: true  # for classification tasks

# Model Configuration
models:
  # List of models to train (order matters for priority)
  roster: ["logreg", "rf", "torch_mlp"]
  
  # Logistic Regression
  logreg:
    solver: "lbfgs"
    max_iter: 1000
    random_state: 42
    optuna_trials: 20
    optuna_params:
      C: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
      penalty: ["l1", "l2"]
      class_weight: ["balanced", null]
  
  # Random Forest
  rf:
    n_estimators: 100
    max_depth: null
    min_samples_split: 2
    min_samples_leaf: 1
    random_state: 42
    optuna_trials: 30
    optuna_params:
      n_estimators: [50, 100, 200, 300]
      max_depth: [3, 5, 7, 10, null]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
      max_features: ["sqrt", "log2", null]
  
  # XGBoost (optional - gracefully skipped if not installed)
  xgboost:
    n_estimators: 100
    learning_rate: 0.1
    max_depth: 6
    random_state: 42
    optuna_trials: 25
    optuna_params:
      n_estimators: [50, 100, 200]
      learning_rate: [0.01, 0.05, 0.1, 0.2]
      max_depth: [3, 4, 5, 6, 7]
      subsample: [0.8, 0.9, 1.0]
      colsample_bytree: [0.8, 0.9, 1.0]
  
  # LightGBM (optional - gracefully skipped if not installed)
  lightgbm:
    n_estimators: 100
    learning_rate: 0.1
    max_depth: 6
    random_state: 42
    optuna_trials: 25
    optuna_params:
      n_estimators: [50, 100, 200]
      learning_rate: [0.01, 0.05, 0.1, 0.2]
      max_depth: [3, 4, 5, 6, 7]
      subsample: [0.8, 0.9, 1.0]
      colsample_bytree: [0.8, 0.9, 1.0]
  
  # PyTorch MLP
  torch_mlp:
    # Architecture
    hidden_dims: [128, 64, 32]
    dropout: 0.2
    activation: "relu"
    batch_norm: true
    
    # Training
    epochs: 100
    batch_size: 32
    learning_rate: 0.001
    weight_decay: 0.0001
    patience: 10
    min_delta: 0.001
    
    # Advanced features
    amp: true  # Automatic Mixed Precision
    gradient_clip: 1.0
    scheduler: "reduce_lr_on_plateau"
    
    # Optuna tuning
    optuna_trials: 20
    optuna_params:
      hidden_dims: [[64, 32], [128, 64], [256, 128, 64], [512, 256, 128, 64]]
      dropout: [0.1, 0.2, 0.3, 0.4]
      learning_rate: [0.0001, 0.001, 0.01]
      weight_decay: [0.00001, 0.0001, 0.001]
      batch_size: [16, 32, 64]

# Evaluation Configuration
evaluation:
  # Metrics to compute
  metrics:
    classification:
      - "accuracy"
      - "precision"
      - "recall"
      - "f1"
      - "roc_auc"
      - "pr_auc"
    regression:
      - "rmse"
      - "mae"
      - "r2"
      - "mape"
  
  # Threshold optimization for classification
  threshold_optimization:
    enabled: true
    metric: "f1"  # or "fbeta", "custom"
    beta: 1.0  # for F-beta score
  
  # Explainability
  explainability:
    enabled: true
    shap_samples: 100  # Number of samples for SHAP analysis
    permutation_importance: true
    feature_importance: true

# Model Registry Configuration
registry:
  # MLflow settings
  experiment_name: "mlops-project"
  registry_name: "mlops-models"
  
  # Promotion rules
  promotion:
    staging_threshold: 0.7  # Minimum score to move to Staging
    production_threshold: 0.8  # Minimum score to move to Production
    metric: "f1"  # or "r2" for regression
  
  # Model versioning
  versioning:
    archive_previous: true  # Archive previous Production model
    max_versions: 10  # Keep last N versions

# MLflow Configuration
mlflow:
  tracking_uri: "./mlruns"  # Default local URI
  artifact_location: "./mlruns"
  experiment_name: "mlops-project"
  
  # Model logging
  log_artifacts: true
  log_model_signature: true
  log_input_example: true
  
  # Custom metrics and artifacts
  custom_metrics: true
  custom_artifacts: true

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "./logs/mlops.log"
  
  # Structured logging
  structured: true
  json_format: false
  
  # MLflow logging
  mlflow_logging: true

# Feature Engineering
features:
  # Preprocessing
  numeric:
    imputation: "median"  # mean, median, constant
    scaling: "standard"  # standard, minmax, robust
    outlier_handling: "iqr"  # iqr, zscore, none
  
  categorical:
    imputation: "constant"  # constant, mode, none
    encoding: "onehot"  # onehot, ordinal, target
    handle_unknown: "ignore"  # ignore, error
  
  # Feature selection
  selection:
    enabled: false
    method: "mutual_info"  # mutual_info, f_classif, f_regression
    k_features: 20

# System Configuration
system:
  # Random seeds
  random_seed: 42
  
  # Parallel processing
  n_jobs: -1  # Use all available cores
  
  # Memory management
  memory_efficient: true
  
  # GPU settings
  gpu:
    enabled: true
    device: "auto"  # auto, cuda, cpu
    memory_fraction: 0.8
  
  # Reproducibility
  deterministic: true
  cudnn_deterministic: true
  cudnn_benchmark: false

# Paths and Artifacts
paths:
  # Data artifacts
  data_artifacts: "./artifacts/data"
  feature_artifacts: "./artifacts/features"
  model_artifacts: "./artifacts/models"
  
  # Reports and visualizations
  reports: "./artifacts/reports"
  plots: "./artifacts/plots"
  
  # Temporary files
  temp: "./temp"
  
  # Logs
  logs: "./logs"
